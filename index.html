<html>
  <head>
    <style>
      #results {
        position: fixed;
        top: 50px;
        left: 10px;
        color: white;
      }

      #results span {
        margin: 5px 5px;
      }

      video {
        position: fixed;
        top: 0;
        left: 0;
      }

      h1 {
        position: fixed;
        bottom: 0;
        left: 0;
      }

      button {
        position: fixed;
        top: 0;
        left: 0;
      }
      #imageInput {
        position: fixed;
        top: 0;
        left: 250;
      }
      #vision_button_image {
        position: fixed;
        top: 0;
        left: 100;
      }
    </style>
  </head>
  <body>
    <!-- Basic Cloud Vision (Google) Demo -->

    <video autoplay="true" id="videoElement"></video>
    <button id="vision_button">Analyze</button>
    <input id="imageInput" type="file" accept="images/*" />
    <button id="vision_button_image">Analyze Image</button>
    <div id="results"></div>

    <script>
      // Access camera
      var video = document.querySelector("#videoElement")
      if (navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices
          .getUserMedia({ video: true })
          .then(function (stream) {
            video.srcObject = stream
          })
          .catch(function (err) {
            console.log("Something went wrong!")
          })
      }

      // We only get to work when the vision button is clicked for video
      document
        .querySelector("#vision_button")
        .addEventListener("click", (evt) => {
          captureAndAnalyze("video")
        })

      // We only get to work when the vision button is clicked for image
      document
        .querySelector("#vision_button_image")
        .addEventListener("click", (evt) => {
          captureAndAnalyze("image")
        })

      // Function to capture either video frame or image and analyze
      function captureAndAnalyze(type) {
        var canvas = document.createElement("canvas")
        var context = canvas.getContext("2d")
        var scale = 0.25

        if (type === "video") {
          canvas.width = video.videoWidth * scale
          canvas.height = video.videoHeight * scale
          context.drawImage(video, 0, 0, canvas.width, canvas.height)
          processImage(canvas.toDataURL())
        } else if (type === "image") {
          var imageInput = document.getElementById("imageInput")
          var image = new Image()
          image.onload = function () {
            console.log("Image loaded successfully:", image.src)
            canvas.width = image.width * scale
            canvas.height = image.height * scale
            context.drawImage(image, 0, 0, canvas.width, canvas.height)
            processImage(canvas.toDataURL())
          }
          image.src = URL.createObjectURL(imageInput.files[0])
        }

        var dataUrl = canvas.toDataURL()
        function processImage(dataUrl) {
          fetch(
            "https://vision.googleapis.com/v1/images:annotate?key=AIzaSyAbhB48NIl4Us5A5M0QcQqIKp-5OqgUksk",
            {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
              },
              body: JSON.stringify({
                requests: [
                  {
                    features: {
                      type: "OBJECT_LOCALIZATION",
                      maxResults: 10,
                    },
                    image: {
                      content: dataUrl.substring(
                        "data:image/png;base64,".length
                      ),
                    },
                  },
                ],
              }),
            }
          )
            .then((resp) => {
              return resp.json()
            })

            .then((json) => {
              // Simply output the response
              console.log(json)
              results.innerHTML = ""
              if (
                json.responses &&
                json.responses.length > 0 &&
                json.responses[0].localizedObjectAnnotations
              ) {
                json.responses[0].localizedObjectAnnotations.forEach(
                  (annotation) => {
                    let description = document.createElement("span")
                    let score = document.createElement("span")

                    let div = document.createElement("div")
                    description.innerText = annotation.name

                    div.append(description)

                    results.append(div)
                  }
                )
              } else {
                results.innerText = "No objects detected in the image."
              }
            })
        }
      }
    </script>
  </body>
</html>
